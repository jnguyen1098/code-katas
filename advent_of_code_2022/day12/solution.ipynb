{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [Advent of Code 2022 Day 12](https://adventofcode.com/2022/day/12)\n",
    "dadada"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initial setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "import pytest\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from ansi import *\n",
    "from comp import *\n",
    "ipytest.autoconfig()\n",
    "PART_ONE_SENTINEL = 0x3f3f3f3f + 1\n",
    "PART_TWO_SENTINEL = 0x3f3f3f3f + 2\n",
    "run_doctest_for = lambda func: doctest.run_docstring_examples(func, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test Cases\n",
    "dadada"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Part 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PART_ONE_CASES: dict[str, dict[str, str | int]] = {\n",
    "    \"example\": {\n",
    "        \"example1\": PART_ONE_SENTINEL,\n",
    "    },\n",
    "    \"input\": {\n",
    "        \"input1\": PART_ONE_SENTINEL,\n",
    "    },\n",
    "}\n",
    "PART_ONE_INPUTS: dict[str, dict[str, str | int]] = {\n",
    "    key: {} for key in PART_ONE_CASES.keys()\n",
    "}\n",
    "PART_ONE_OUTPUTS: dict[str, dict[str, str | int]] = {\n",
    "    key: {} for key in PART_ONE_CASES.keys()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Part 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PART_TWO_CASES: dict[str, dict[str, str | int]] = {\n",
    "    \"example\": {\n",
    "        \"example1\": PART_TWO_SENTINEL,\n",
    "    },\n",
    "    \"input\": {\n",
    "        \"input1\": PART_TWO_SENTINEL,\n",
    "    },\n",
    "}\n",
    "PART_TWO_INPUTS: dict[str, dict[str, str | int]] = {\n",
    "    key: {} for key in PART_TWO_CASES.keys()\n",
    "}\n",
    "PART_TWO_OUTPUTS: dict[str, dict[str, str | int]] = {\n",
    "    key: {} for key in PART_TWO_CASES.keys()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Input Parsing\n",
    "dadada"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Model(BaseModel):\n",
    "    line: str\n",
    "\n",
    "def parse_input_from_filename(filename: str) -> Context:\n",
    "    lines = list(yield_line(filename))\n",
    "\n",
    "    ctx = Context()\n",
    "    ctx.input = []\n",
    "\n",
    "    input_lines = ctx.input\n",
    "\n",
    "    for idx, line in enumerate(lines):\n",
    "        construct = {\"line\": line}\n",
    "        input_lines.append(Model(**construct))\n",
    "\n",
    "    return ctx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Parsing Examples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%ipytest -xrPvvvvv\n",
    "@pytest.mark.parametrize(\"test_file_name\", PART_ONE_CASES[\"example\"].keys() | PART_TWO_CASES[\"example\"].keys())\n",
    "def test_parsing_examples(test_file_name):\n",
    "    for entity in parse_input_from_filename(test_file_name).input:\n",
    "        log(f\"{entity}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Parsing Inputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%ipytest -xrPvvvvv\n",
    "@pytest.mark.parametrize(\"test_file_name\", PART_ONE_CASES[\"input\"].keys() | PART_TWO_CASES[\"input\"].keys())\n",
    "def test_parsing_inputs(test_file_name):\n",
    "    for entity in parse_input_from_filename(test_file_name).input:\n",
    "        log(f\"{entity}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper 1\n",
    "dadada"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%ipytest -xrPvvvvv\n",
    "def return_sentinel_for_part(part: int) -> int:\n",
    "    \"\"\"\n",
    "    Returns the proper sentinel for AOC.\n",
    "\n",
    "    :param part: the round of AOC\n",
    "    :return: the sentinel\n",
    "    \"\"\"\n",
    "    if part == 1:\n",
    "        return PART_ONE_SENTINEL\n",
    "    if part == 2:\n",
    "        return PART_TWO_SENTINEL\n",
    "    raise NotImplementedError(f\"Bad {part=}\")\n",
    "\n",
    "def test_return_sentinel_for_part() -> None:\n",
    "    assert return_sentinel_for_part(1) == PART_ONE_SENTINEL\n",
    "    assert return_sentinel_for_part(2) == PART_TWO_SENTINEL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main Function\n",
    "dadada"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def solve(part: int, filename: str) -> int:\n",
    "    stuff = parse_input_from_filename(filename).input\n",
    "    if part == 1:\n",
    "        disable_logging()\n",
    "        return return_sentinel_for_part(1)\n",
    "    if part == 2:\n",
    "        disable_logging()\n",
    "        return return_sentinel_for_part(2)\n",
    "    else:\n",
    "        raise Exception(f\"Invalid part: {part}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Execution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Part 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%ipytest -xrPvvvvv\n",
    "@pytest.mark.parametrize(\"test_file_name, test_expected_output\", PART_ONE_CASES[\"example\"].items())\n",
    "def test_part_one_examples(test_file_name, test_expected_output):\n",
    "    test_actual_output = solve(1, test_file_name)\n",
    "    PART_ONE_OUTPUTS[\"example\"][test_file_name] = test_actual_output\n",
    "    failure_message = \"Did you forget to calibrate the example test case?\" if (\n",
    "        test_expected_output == PART_ONE_SENTINEL\n",
    "    ) else f\"Failed example test case: expected {test_expected_output} but got {test_actual_output}\"\n",
    "    assert test_actual_output == test_expected_output, failure_message\n",
    "\n",
    "@pytest.mark.parametrize(\"test_file_name, test_expected_output\", PART_ONE_CASES[\"input\"].items())\n",
    "def test_part_one_inputs(test_file_name, test_expected_output):\n",
    "    test_actual_output = solve(1, test_file_name)\n",
    "    PART_ONE_OUTPUTS[\"input\"][test_file_name] = test_actual_output\n",
    "    failure_message = f\"Candidate answer {test_actual_output} found\" if (\n",
    "        test_expected_output == PART_ONE_SENTINEL\n",
    "    ) else f\"Failed input test case: expected {test_expected_output} but got {test_actual_output}\"\n",
    "    assert test_actual_output == test_expected_output, failure_message"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Part 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%ipytest -xrPvvvvv\n",
    "@pytest.mark.parametrize(\"test_file_name, test_expected_output\", PART_TWO_CASES[\"example\"].items())\n",
    "def test_part_two_examples(test_file_name, test_expected_output):\n",
    "    test_actual_output = solve(2, test_file_name)\n",
    "    PART_TWO_OUTPUTS[\"example\"][test_file_name] = test_actual_output\n",
    "    failure_message = \"Did you forget to calibrate the example test case?\" if (\n",
    "        test_expected_output == PART_TWO_SENTINEL\n",
    "    ) else f\"Failed example test case: expected {test_expected_output} but got {test_actual_output}\"\n",
    "    assert test_actual_output == test_expected_output, failure_message\n",
    "\n",
    "@pytest.mark.parametrize(\"test_file_name, test_expected_output\", PART_TWO_CASES[\"input\"].items())\n",
    "def test_part_two_inputs(test_file_name, test_expected_output):\n",
    "    test_actual_output = solve(2, test_file_name)\n",
    "    PART_TWO_OUTPUTS[\"input\"][test_file_name] = test_actual_output\n",
    "    failure_message = f\"Candidate answer {test_actual_output} found\" if (\n",
    "        test_expected_output == PART_TWO_SENTINEL\n",
    "    ) else f\"Failed input test case: expected {test_expected_output} but got {test_actual_output}\"\n",
    "    assert test_actual_output == test_expected_output, failure_message"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "dadada"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
